{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96c49f3c-9298-4cea-8016-a5d0a5ecdbe8",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a913270c-7584-4643-b595-42d92700fbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e61906-e2d9-46e8-bcd8-1d80d7d3a940",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "225fa933-5c76-41f3-b2a0-074926d179ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_X = pd.read_csv(\"./deep_occupancy_detection/data/1_X_train.csv\").values\n",
    "target_X = pd.read_csv(\"./deep_occupancy_detection/data/2_X_train.csv\").values\n",
    "\n",
    "source_y_task = pd.read_csv(\"./deep_occupancy_detection/data/1_Y_train.csv\").values.reshape(-1)\n",
    "target_y_task = pd.read_csv(\"./deep_occupancy_detection/data/2_Y_train.csv\").values.reshape(-1)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(source_X)\n",
    "source_X = scaler.transform(source_X)\n",
    "target_X = scaler.transform(target_X)\n",
    "\n",
    "source_target_X = np.concatenate([source_X, target_X], axis=0)\n",
    "source_target_y_domain = np.concatenate([np.zeros(source_X.shape[0]), np.ones(target_X.shape[0])], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36af3035-f321-456a-8a70-3bdbe836d190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 2. Marginal Distribution Discrepancy between Source and Target\n",
    "source_target_X = torch.Tensor(source_target_X)\n",
    "source_target_y_domain = torch.Tensor(source_target_y_domain)\n",
    "\n",
    "source_target_X = source_target_X.to(utils.DEVICE)\n",
    "source_target_y_domain = source_target_y_domain.to(utils.DEVICE)\n",
    "\n",
    "source_target_ds = TensorDataset(source_target_X, source_target_y_domain)\n",
    "source_target_loader = DataLoader(source_target_ds, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f24b09dc-7578-41c1-9f9d-d3cbd9ed5fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 3. Common Model Minimizin Loss of Both Domains\n",
    "source_X = torch.Tensor(source_X)\n",
    "target_X = torch.Tensor(target_X)\n",
    "source_y_task = torch.Tensor(source_y_task)\n",
    "target_y_task = torch.Tensor(target_y_task)\n",
    "\n",
    "source_X = source_X.to(utils.DEVICE)\n",
    "target_X = target_X.to(utils.DEVICE)\n",
    "source_y_task = source_y_task.to(utils.DEVICE)\n",
    "target_y_task = target_y_task.to(utils.DEVICE)\n",
    "\n",
    "source_ds = TensorDataset(source_X, source_y_task)\n",
    "target_ds = TensorDataset(target_X, target_y_task)\n",
    "\n",
    "source_loader = DataLoader(source_ds, batch_size=16, shuffle=True)\n",
    "target_loader = DataLoader(target_ds, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751351d7-de2d-44cb-a54c-af83fc9b81d7",
   "metadata": {},
   "source": [
    "# 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e53349d-11f2-42fa-aeca-ddf55436738f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffcd8ada-f5b3-434e-9ffc-dd4dbe1ccbc0",
   "metadata": {},
   "source": [
    "# 2. Marginal Distribution Discrepancy between Source and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e40f6ca8-0792-416d-ae4f-12fae2f99a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "num_repeats = 10\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80d838c1-4d0a-453a-a5ac-56fe6ce60592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain Classification Accuracy: 0.7404029846191407\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "for _ in range(num_repeats):\n",
    "    domain_classifier = utils.Decoder(input_size=source_target_X.shape[1], output_size=1).to(utils.DEVICE)\n",
    "    optimizer = optim.Adam(domain_classifier.parameters(), lr=0.001)\n",
    "\n",
    "    for _ in range(num_epochs):\n",
    "        for source_target_X_batch, source_target_y_domain_batch in source_target_loader:\n",
    "            # Forward\n",
    "            pred_y = domain_classifier(source_target_X_batch)\n",
    "            pred_y = torch.sigmoid(pred_y).reshape(-1)\n",
    "            loss = criterion(pred_y, source_target_y_domain_batch)\n",
    "\n",
    "            # Backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # Update Params\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluation\n",
    "    pred_y = domain_classifier(source_target_X)\n",
    "    pred_y = torch.sigmoid(pred_y).reshape(-1)\n",
    "    pred_y = pred_y > 0.5\n",
    "\n",
    "    acc = sum(pred_y == source_target_y_domain) / source_target_y_domain.shape[0]\n",
    "    accs.append(acc.item())\n",
    "\n",
    "print(f\"Domain Classification Accuracy: {np.mean(accs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbab0609-f9b6-406d-8b33-ff63f4015795",
   "metadata": {},
   "source": [
    "# 3. Common Model Minimizin Loss of Both Domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "130c172d-99a3-4aec-a05d-89b73ac53bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common Model's Cross Entropy Loss: 0.6571887731552124\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for _ in range(num_repeats):\n",
    "    task_classifier = utils.Decoder(input_size=source_X.shape[1], output_size=1).to(utils.DEVICE)\n",
    "    optimizer = optim.Adam(task_classifier.parameters(), lr=0.001)\n",
    "    for _ in range(num_epochs):\n",
    "        for (source_X_batch, source_y_task_batch), (target_X_batch, target_y_task_batch) in zip(source_loader, target_loader):\n",
    "            # Forward\n",
    "            pred_source_y_task = task_classifier(source_X_batch)\n",
    "            pred_target_y_task = task_classifier(target_X_batch)\n",
    "            pred_source_y_task = torch.sigmoid(pred_source_y_task).reshape(-1)\n",
    "            pred_target_y_task = torch.sigmoid(pred_target_y_task).reshape(-1)\n",
    "            loss = criterion(pred_source_y_task, source_y_task_batch)\n",
    "            loss += criterion(pred_target_y_task, target_y_task_batch)\n",
    "\n",
    "            # Backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # Update Params\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluation\n",
    "    pred_y = task_classifier(source_X)\n",
    "    pred_y = torch.sigmoid(pred_y).reshape(-1)\n",
    "    loss = criterion(pred_y, source_y_task)\n",
    "\n",
    "    pred_y = task_classifier(target_X)\n",
    "    pred_y = torch.sigmoid(pred_y).reshape(-1)\n",
    "    loss += criterion(pred_y, target_y_task)\n",
    "    losses.append(loss.item())\n",
    "\n",
    "print(f\"Common Model's Cross Entropy Loss: {np.mean(losses)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
